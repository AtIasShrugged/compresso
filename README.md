# Compresso

**Compresso** â€” Fast LLM Summarizer for Text, Articles, and YouTube videos

A minimal, full-stack Python application built with FastAPI and clean architecture principles.

## âœ¨ Features

- **Three Summarization Modes**
  - ğŸ“ Text - Direct text input
  - ğŸ“° Article URL - Automatic article extraction
  - ğŸ¥ YouTube - Video transcript with timestamps

- **Flexible Options**
  - Detail levels: Short, Medium, Long
  - Multiple LLM models: GPT-4o, Claude 3.5, and more
  - Timestamp support for video summaries

- **Modern UI/UX**
  - ğŸŒ“ Dark/Light theme with system preference detection
  - ğŸŒ RU/EN localization
  - ğŸ“± Responsive design

- **Built for Production**
  - âš¡ï¸ FastAPI + Jinja2 SSR
  - ğŸ” Session-based authentication (no database required)
  - ğŸ§° Redis caching for recent summaries
  - ğŸ“Š Structured logging
  - ğŸ—ï¸ Clean architecture (domain, infrastructure, presentation layers)

## ğŸš€ Quick Start (Development)

### Prerequisites

- Python 3.11+
- Redis (local or Docker)
- OpenAI and/or Anthropic API keys

### Installation

1. **Clone and setup**
   ```bash
   git clone <repository-url>
   cd compresso
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

   Required environment variables:
   ```ini
   APP_SECRET=your-secret-key-here
   APP_LOGIN_PASSWORD=your-password
   OPENAI_API_KEY=sk-...
   ANTHROPIC_API_KEY=sk-ant-...
   REDIS_URL=redis://localhost:6379/0
   ```

4. **Start Redis**
   ```bash
   # Using Docker
   docker run -d -p 6379:6379 redis:7
   
   # Or use local Redis
   redis-server
   ```

5. **Run application**
   ```bash
   uvicorn app.main:app --reload
   ```

6. **Open browser**
   ```
   http://localhost:8000
   ```

   Default credentials:
   - Username: `admin`
   - Password: (as set in `.env`)

## ğŸ“ Project Structure

```
compresso/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/              # Domain layer
â”‚   â”‚   â”œâ”€â”€ entities/      # Business entities
â”‚   â”‚   â”œâ”€â”€ ports/         # Port interfaces
â”‚   â”‚   â””â”€â”€ usecases/      # Business logic
â”‚   â”œâ”€â”€ infra/             # Infrastructure layer
â”‚   â”‚   â”œâ”€â”€ llm/           # LLM clients (OpenAI, Anthropic)
â”‚   â”‚   â”œâ”€â”€ transcript/    # URL & YouTube providers
â”‚   â”‚   â”œâ”€â”€ cache/         # Redis cache
â”‚   â”‚   â”œâ”€â”€ i18n/          # Localization
â”‚   â”‚   â””â”€â”€ auth/          # Authentication
â”‚   â”œâ”€â”€ web/               # Presentation layer
â”‚   â”‚   â”œâ”€â”€ routes/        # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ templates/     # Jinja2 templates
â”‚   â”‚   â””â”€â”€ static/        # CSS, JS
â”‚   â”œâ”€â”€ config/            # Configuration
â”‚   â””â”€â”€ main.py            # FastAPI app
â”œâ”€â”€ locales/               # Translation files
â”œâ”€â”€ prompts/               # LLM prompt templates
â”œâ”€â”€ instructions/          # Project documentation
â””â”€â”€ requirements.txt
```

## ğŸ”§ Configuration

See `.env.example` for all configuration options.

### Key Settings

- `APP_ENV`: `dev` or `prod`
- `APP_SECRET`: Secret key for session signing
- `CACHE_MAX_ITEMS`: Maximum cached summaries (default: 50)
- `WHISPER_MODE`: `local` or `openai` for video transcription
- `LLM_DEFAULT`: Default model (e.g., `openai:gpt-4o-mini`)

## ğŸŒ Localization

Translations are stored in `locales/{lang}.json`. Supported languages:
- English (`en`)
- Russian (`ru`)

To add a new language:
1. Create `locales/{lang}.json`
2. Add to `APP_ALLOWED_LOCALES` in `.env`

## ğŸ¨ Theming

The application supports light/dark themes with:
- System preference detection
- Manual toggle
- LocalStorage persistence
- CSS variables for easy customization

Edit `app/web/static/css/main.css` to customize colors.

## ğŸ“ Prompt Templates

Prompt templates are in `prompts/{lang}/{mode}_{detail}.txt`:
- `text_short.txt`, `text_medium.txt`, `text_long.txt`
- `url_short.txt`, `url_medium.txt`, `url_long.txt`
- `youtube_short.txt`, `youtube_medium.txt`, `youtube_long.txt`

## ğŸš€ Deployment on Render

1. **Create Web Service** on [Render.com](https://render.com)

2. **Configuration**:
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `uvicorn app.main:app --host 0.0.0.0 --port $PORT`

3. **Environment Variables**:
   Set all required variables from `.env.example`
   - Set `APP_ENV=prod`
   - Use Render's managed Redis add-on or external Redis URL

4. **(Optional) Custom Domain**: Configure in Render dashboard

## ğŸ§ª Testing

```bash
# Run tests (when implemented)
pytest

# Type checking
mypy app

# Linting
ruff check app
```

## ğŸ“„ API Documentation

When running in development mode, API docs are available at:
- Swagger UI: http://localhost:8000/api/docs
- ReDoc: http://localhost:8000/api/redoc

## ğŸ—ï¸ Architecture

**Clean Architecture** with three layers:

1. **Domain (Core)**
   - Entities: `SummaryOptions`, `SummaryResult`
   - Ports: Interfaces for LLM, Transcript, Cache
   - Use Cases: Business logic

2. **Infrastructure**
   - Adapters implementing ports
   - External services (OpenAI, Anthropic, Redis)
   - I18n, Authentication

3. **Presentation (Web)**
   - FastAPI routes
   - Jinja2 templates
   - Static assets

## ğŸ”’ Security

- Session-based authentication with signed cookies
- HttpOnly, Secure, SameSite cookies in production
- Input size limits (100k characters)
- No sensitive data in logs
- Secrets via environment variables

## ğŸ“š Tech Stack

- **Backend**: FastAPI, Uvicorn
- **Templates**: Jinja2
- **Styling**: CSS with variables
- **LLM**: OpenAI, Anthropic
- **Transcription**: youtube-transcript-api, yt-dlp, Whisper
- **Cache**: Redis
- **Extraction**: BeautifulSoup4, readability-lxml
- **Logging**: Loguru
- **Config**: Pydantic Settings

## ğŸ“– License

MIT

## ğŸ¤ Contributing

Contributions are welcome! Please follow the clean architecture principles and existing code style.

## ğŸ“§ Contact

For issues and questions, please open a GitHub issue.
